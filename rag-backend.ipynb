{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ RAG Pipeline - Kaggle Backend with Ngrok\n",
    "\n",
    "This notebook sets up a complete RAG backend with FastAPI and exposes it via ngrok.\n",
    "\n",
    "**Prerequisites:**\n",
    "1. Enable **Internet** in Kaggle notebook settings\n",
    "2. Get your ngrok auth token from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
    "\n",
    "**Run cells in order!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CELL 1: Install Dependencies\n",
    "!pip install fastapi uvicorn pyngrok python-multipart --quiet\n",
    "!pip install torch transformers faiss-cpu rank_bm25 rouge_score sentence-transformers PyPDF2 --quiet\n",
    "!pip install scikit-learn psutil nltk pydantic --quiet\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CELL 2: Configure Ngrok\n",
    "from pyngrok import ngrok, conf\n",
    "\n",
    "# ‚ö†Ô∏è REPLACE WITH YOUR NGROK TOKEN!\n",
    "NGROK_AUTH_TOKEN = \"YOUR_NGROK_TOKEN_HERE\"\n",
    "\n",
    "conf.get_default().auth_token = NGROK_AUTH_TOKEN\n",
    "print(\"‚úÖ Ngrok configured successfully!\")\n",
    "print(\"üìù Don't have a token? Get one at: https://dashboard.ngrok.com/signup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CELL 3: Import Libraries\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "from PyPDF2 import PdfReader\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rank_bm25 import BM25Okapi\n",
    "import torch\n",
    "import io\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer, util\n",
    "import psutil\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "try:\n",
    "    import faiss\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è FAISS not available\")\n",
    "    faiss = None\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "print(\"‚úÖ Libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CELL 4: Paste Your RAG Code Here\n",
    "# Copy all your chunking functions and OptimizedRAG class from your existing notebook\n",
    "# For example:\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text.strip())\n",
    "    text = re.sub(r'[^\\x20-\\x7E]', '', text)\n",
    "    return text\n",
    "\n",
    "def read_pdf_from_bytes(pdf_bytes):\n",
    "    \"\"\"Read PDF from bytes\"\"\"\n",
    "    try:\n",
    "        pdf_file = io.BytesIO(pdf_bytes)\n",
    "        reader = PdfReader(pdf_file)\n",
    "        pages = []\n",
    "        for page in reader.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                pages.append(text)\n",
    "        return pages\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []\n",
    "\n",
    "# TODO: Add your chunking methods here\n",
    "# - chunk_with_overlap\n",
    "# - Gradient_chunking\n",
    "# - Gradient_chunking_final\n",
    "# - etc.\n",
    "\n",
    "# TODO: Add your evaluate_chunk_quality function here\n",
    "\n",
    "# TODO: Add your OptimizedRAG class here\n",
    "\n",
    "print(\"‚úÖ RAG functions loaded! (Make sure you pasted your code above)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CELL 5: FastAPI Setup\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "import uvicorn\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "app = FastAPI(title=\"RAG Pipeline API\")\n",
    "\n",
    "# CORS\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# Models\n",
    "class RAGConfig(BaseModel):\n",
    "    chunkSize: int = 500\n",
    "    overlap: int = 50\n",
    "    method: str = \"gradient\"\n",
    "    useBM25: bool = True\n",
    "    useCosine: bool = True\n",
    "    useFaiss: bool = False\n",
    "    rerankEnabled: bool = True\n",
    "    topK: int = 4\n",
    "\n",
    "class ProcessRequest(BaseModel):\n",
    "    text: str\n",
    "    query: str\n",
    "    config: RAGConfig\n",
    "\n",
    "class ChunkData(BaseModel):\n",
    "    id: int\n",
    "    content: str\n",
    "\n",
    "class MetricsData(BaseModel):\n",
    "    num_chunks: int\n",
    "    weighted_score: float\n",
    "    latency: float\n",
    "    avg_coherence: float\n",
    "    context_preservation: float\n",
    "    avg_information_density: float\n",
    "    coverage: float\n",
    "    semantic_coverage: float\n",
    "    cpu_usage: float\n",
    "    memory_usage: float\n",
    "\n",
    "class RAGResponse(BaseModel):\n",
    "    response: str\n",
    "    chunks: List[ChunkData]\n",
    "    retrievedChunks: List[int]\n",
    "    metrics: MetricsData\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\"message\": \"RAG Pipeline API\", \"status\": \"healthy\"}\n",
    "\n",
    "@app.post(\"/upload-document\")\n",
    "async def upload_document(file: UploadFile = File(...)):\n",
    "    try:\n",
    "        content = await file.read()\n",
    "        if not file.filename.endswith('.pdf'):\n",
    "            raise HTTPException(400, \"Only PDF files\")\n",
    "        \n",
    "        documents = read_pdf_from_bytes(content)\n",
    "        if not documents:\n",
    "            raise HTTPException(400, \"Could not extract text\")\n",
    "        \n",
    "        return {\n",
    "            \"filename\": file.filename,\n",
    "            \"extracted_text\": \" \".join(documents),\n",
    "            \"message\": \"Success\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise HTTPException(500, str(e))\n",
    "\n",
    "@app.post(\"/process\", response_model=RAGResponse)\n",
    "async def process_rag(request: ProcessRequest):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        process = psutil.Process()\n",
    "        memory_start = process.memory_info().rss / 1024 / 1024\n",
    "        \n",
    "        # Method mapping\n",
    "        method_map = {\n",
    "            \"fixed\": \"fixed\",\n",
    "            \"gradient\": \"Gradient_chunking\",\n",
    "            \"gradient_final\": \"Gradient_chunking_final\"\n",
    "        }\n",
    "        \n",
    "        # Build config\n",
    "        rag_config = {\n",
    "            \"chunking_method\": method_map.get(request.config.method, \"Gradient_chunking\"),\n",
    "            \"chunk_size\": request.config.chunkSize,\n",
    "            \"overlap\": request.config.overlap,\n",
    "            \"use_bm25\": request.config.useBM25,\n",
    "            \"use_cosine\": request.config.useCosine,\n",
    "            \"use_faiss\": request.config.useFaiss,\n",
    "            \"rerank_enabled\": request.config.rerankEnabled,\n",
    "            \"top_k\": request.config.topK,\n",
    "        }\n",
    "        \n",
    "        # Initialize RAG\n",
    "        rag = OptimizedRAG([request.text], **rag_config)\n",
    "        \n",
    "        # Retrieve and generate\n",
    "        retrieved = rag.retrieve(request.query)\n",
    "        response_text = rag.generate_answer(request.query, retrieved)\n",
    "        \n",
    "        # Metrics\n",
    "        latency = time.time() - start_time\n",
    "        memory_end = process.memory_info().rss / 1024 / 1024\n",
    "        memory_usage = max(memory_end - memory_start, 0.0)\n",
    "        cpu_usage = process.cpu_percent(interval=0.1)\n",
    "        \n",
    "        quality = evaluate_chunk_quality(rag.chunks, request.text)\n",
    "        \n",
    "        # Find retrieved indices\n",
    "        retrieved_indices = []\n",
    "        for rc in retrieved:\n",
    "            for idx, chunk in enumerate(rag.chunks):\n",
    "                if chunk == rc:\n",
    "                    retrieved_indices.append(idx)\n",
    "                    break\n",
    "        \n",
    "        return RAGResponse(\n",
    "            response=response_text,\n",
    "            chunks=[ChunkData(id=i, content=c) for i, c in enumerate(rag.chunks)],\n",
    "            retrievedChunks=retrieved_indices,\n",
    "            metrics=MetricsData(\n",
    "                num_chunks=len(rag.chunks),\n",
    "                weighted_score=quality[\"weighted_score\"],\n",
    "                latency=latency * 1000,\n",
    "                avg_coherence=quality[\"avg_coherence\"],\n",
    "                context_preservation=quality[\"context_preservation\"],\n",
    "                avg_information_density=quality[\"avg_information_density\"],\n",
    "                coverage=quality[\"coverage\"],\n",
    "                semantic_coverage=quality[\"semantic_coverage\"],\n",
    "                cpu_usage=cpu_usage,\n",
    "                memory_usage=memory_usage\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise HTTPException(500, str(e))\n",
    "\n",
    "print(\"‚úÖ FastAPI app configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CELL 6: Start Server with Ngrok\n",
    "import threading\n",
    "\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
    "\n",
    "# Start server\n",
    "server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n",
    "time.sleep(3)\n",
    "\n",
    "# Start ngrok\n",
    "public_url = ngrok.connect(8000)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üöÄ RAG PIPELINE API IS LIVE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"üì° Public URL: {public_url}\")\n",
    "print(f\"üìù Docs: {public_url}/docs\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\")\n",
    "print(\"‚úÖ Copy this URL and update it in your React frontend!\")\n",
    "print(\"\")\n",
    "print(\"Update apiService.js:\")\n",
    "print(f\"const API_BASE_URL = '{public_url}';\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CELL 7: Test API\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{public_url}/\")\n",
    "    print(\"‚úÖ API Test Successful!\")\n",
    "    print(f\"Response: {response.json()}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CELL 8: Keep Alive (Keep this running!)\n",
    "print(f\"üîÑ Server running at: {public_url}\")\n",
    "print(\"üí° Keep this cell running to maintain connection\")\n",
    "print(\"‚ö†Ô∏è Free ngrok sessions timeout after 2 hours\")\n",
    "print(\"\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(60)\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nüõë Server stopped\")\n",
    "    ngrok.kill()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
